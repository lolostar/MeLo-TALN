\section{Extraction de termes avec Word2Vec}

\subsection{Présentation des données}
Nous avons entraîné un modèle Word2Vec sur un corpus de comptes rendus de maintenance. Ce corpus contient environ 8000 fiches de maintenance. Si la taille de ce corpus semble restreinte, nous avons néanmoins obtenu des résultats concluants (fig \ref{fig:w2v}), les textes étant très répétitifs. En effet, la taille de notre dictionnaire est d'environ 5000 mots après prétraitements. Nous avons également calculé l'indice de richesse lexicale \cite{McKee2000}, quotient entre le nombre d’occurrences d’un token et le nombre total de tokens du texte. Un token est défini comme formé exclusivement de caractères alphabétiques, sans distinguer majuscules et minuscules. Notre corpus comprend 97 065 tokens dont 5887 tokens uniques donnant une richesse lexicale de 0.0607 avant prétraitements.


\subsection{Algorithme}

Nous avons mis en place un script python qui effectue plusieurs opérations. Il est ainsi possible de charger un corpus local ou de récupérer des données externes avec Elasticsearch\footnote{www.elastic.co}.
Un ensemble de prétraitements est ensuite appliqué sur les données à savoir la suppression des caractères non désirés, le découpage en phrases et en mots. Concernant ces deux dernières étapes, nous avons utilisé la fonction dédiée du package NLTK. Nous sommes également partis de l'hypothèse que l'apprentissage de Word2Vec serait plus fin avec l'ajout de métadonnées grammaticales sur les mots de notre corpus. Nous avons donc intégré TreeTagger \cite{Schmid94probabilisticpart-of-speech} à nos traitements pour un étiquetage morphosyntaxique : Word2Vec apprend ainsi sur la forme, le lemme et la catégorie grammaticale du terme. Nous considérons qu'il s'agit d'une première étape de désambiguïsation. À la suite de TreeTagger, les mots vides sont supprimés et nous appelons Word2Vec pour le calcul de la similarité. Une sortie contenant les résultats de Word2Vec au format RDF est alors générée. Cette dernière étape permet de créer une base de connaissance sur les résultats du traitement des documents du corpus contenant les phrases et mots qu'elles contiennent et pour chaque mot du corpus : son label, sa fréquence, sa catégorie morphosyntaxique, son lemme, les 15 premières phrases dans lesquelles il apparaît et les 15 candidats termes les plus similaires (fig \ref{gtype}).
